from utils import StringSlice, Span
from memory import memcpy
import ..io
from ..builtins import copy, panic, index_byte
from .bufio import MAX_CONSECUTIVE_EMPTY_READS


alias MAX_INT: Int = 2147483647


struct Scanner[R: io.Reader, split: SplitFunction = scan_lines]():  # The function to split the tokens.
    """Scanner provides a convenient Interface for reading data such as
    a file of newline-delimited lines of text. Successive calls to
    the [Scanner.Scan] method will step through the 'tokens' of a file, skipping
    the bytes between the tokens. The specification of a token is
    defined by a split function of type [SplitFunction]; the default split
    function breaks the input Into lines with line termination stripped. [Scanner.split]
    fntions are defined in this package for scanning a file Into
    lines, bytes, UTF-8-encoded runes, and space-delimited words. The
    client may instead provide a custom split function.

    Scanning stops unrecoverably at EOF, the first I/O error, or a token too
    large to fit in the [Scanner.buffer]. When a scan stops, the reader may have
    advanced arbitrarily far past the last token. Programs that need more
    control over error handling or large tokens, or must run sequential scans
    on a reader, should use [bufio.Reader] instead."""

    var reader: R  # The reader provided by the client.
    var max_token_size: Int  # Maximum size of a token; modified by tests.
    var token: List[UInt8]  # Last token returned by split.
    var buf: List[UInt8]  # buffer used as argument to split.
    var start: Int  # First non-processed byte in buf.
    var end: Int  # End of data in buf.
    var empties: Int  # Count of successive empty tokens.
    var scan_called: Bool  # Scan has been called; buffer is in use.
    var done: Bool  # Scan has finished.
    var err: Error

    fn __init__(
        inout self,
        owned reader: R,
        max_token_size: Int = MAX_SCAN_TOKEN_SIZE,
        token: List[UInt8] = List[UInt8](capacity=io.BUFFER_SIZE),
        buf: List[UInt8] = List[UInt8](capacity=io.BUFFER_SIZE),
        start: Int = 0,
        end: Int = 0,
        empties: Int = 0,
        scan_called: Bool = False,
        done: Bool = False,
    ):
        self.reader = reader^
        self.max_token_size = max_token_size
        self.token = token
        self.buf = buf
        self.start = start
        self.end = end
        self.empties = empties
        self.scan_called = scan_called
        self.done = done
        self.err = Error()

    fn as_bytes_slice(ref [_]self) -> Span[UInt8, __lifetime_of(self)]:
        """Returns the internal data as a Span[UInt8]."""
        return Span[UInt8, __lifetime_of(self)](self.buf)

    fn current_token_as_bytes_slice(ref [_]self) -> Span[UInt8, __lifetime_of(self)]:
        """Returns the most recent token generated by a call to [Scanner.Scan].
        The underlying array may point to data that will be overwritten
        by a subsequent call to Scan. It does no allocation.
        """
        return Span[UInt8, __lifetime_of(self)](self.token)

    fn current_token_as_string_slice(ref [_]self) -> StringSlice[__lifetime_of(self)]:
        """Returns the most recent token generated by a call to [Scanner.Scan].
        The underlying array may point to data that will be overwritten
        by a subsequent call to Scan. It does no allocation.
        """
        return StringSlice[__lifetime_of(self)](unsafe_from_utf8_ptr=self.token.unsafe_ptr(), len=len(self.token))

    fn current_token_as_bytes(self) -> List[UInt8]:
        """Returns the most recent token generated by a call to [Scanner.Scan].
        The underlying array may point to data that will be overwritten
        by a subsequent call to Scan. It does no allocation.
        """
        return self.token

    fn current_token(self) -> String:
        """Returns the most recent token generated by a call to [Scanner.Scan]
        as a newly allocated string holding its bytes."""
        return self.current_token_as_string_slice()

    fn scan(inout self) -> Bool:
        """Advances the [Scanner] to the next token, which will then be
        available through the [Scanner.current_token_as_bytes] or [Scanner.current_token] method.
        It returns False when there are no more tokens, either by reaching the end of the input or an error.
        After Scan returns False, the [Scanner.Err] method will return any error that
        occurred during scanning, except if it was [io.EOF], [Scanner.Err].
        Scan raises an Error if the split function returns too many empty
        tokens without advancing the input. This is a common error mode for
        scanners.
        """
        if self.done:
            return False

        self.scan_called = True
        # Loop until we have a token.
        while True:
            # See if we can get a token with what we already have.
            # If we've run out of data but have an error, give the split function
            # a chance to recover any remaining, possibly empty token.
            if (self.end > self.start) or self.err:
                var advance: Int
                var token = List[UInt8](capacity=io.BUFFER_SIZE)
                var err = Error()
                var at_eof = False
                if self.err:
                    at_eof = True
                advance, token, err = split(self.as_bytes_slice()[self.start : self.end], at_eof)
                if err:
                    if str(err) == str(ERR_FINAL_TOKEN):
                        self.token = token
                        self.done = True
                        # When token is not nil, it means the scanning stops
                        # with a trailing token, and thus the return value
                        # should be True to indicate the existence of the token.
                        return len(token) != 0

                    self.set_err(err)
                    return False

                if not self.advance(advance):
                    return False

                self.token = token
                if len(token) != 0:
                    if not self.err or advance > 0:
                        self.empties = 0
                    else:
                        # Returning tokens not advancing input at EOF.
                        self.empties += 1
                        if self.empties > MAX_CONSECUTIVE_EMPTY_READS:
                            panic("bufio.Scan: too many empty tokens without progressing")

                    return True

            # We cannot generate a token with what we are holding.
            # If we've already hit EOF or an I/O error, we are done.
            if self.err:
                # Shut it down.
                self.start = 0
                self.end = 0
                return False

            # Must read more data.
            # First, shift data to beginning of buffer if there's lots of empty space
            # or space is needed.
            if self.start > 0 and (self.end == len(self.buf) or self.start > int(len(self.buf) / 2)):
                _ = copy(self.buf, self.as_bytes_slice()[self.start : self.end])
                self.end -= self.start
                self.start = 0

            # Is the buffer full? If so, resize.
            if self.end == len(self.buf):
                # Guarantee no overflow in the multiplication below.
                if len(self.buf) >= self.max_token_size or len(self.buf) > int(MAX_INT / 2):
                    self.set_err((ERR_TOO_LONG))
                    return False

                var new_size = len(self.buf) * 2
                if new_size == 0:
                    new_size = START_BUF_SIZE

                # Make a new List[UInt8] buffer and copy the elements in
                new_size = min(new_size, self.max_token_size)
                var new_buf = List[UInt8](capacity=new_size)
                _ = copy(new_buf, self.buf[self.start : self.end])
                self.buf = new_buf
                self.end -= self.start
                self.start = 0

            # Finally we can read some input. Make sure we don't get stuck with
            # a misbehaving Reader. Officially we don't need to do this, but let's
            # be extra careful: Scanner is for safe, simple jobs.
            var loop = 0
            while True:
                var buf = self.as_bytes_slice()[self.end :]
                # Catch any reader errors and set the internal error field to that err instead of bubbling it up.
                var bytes_read: Int
                var err: Error
                bytes_read, err = self.reader._read(buf, len(buf))
                if bytes_read < 0 or len(buf) - self.end < bytes_read:
                    self.set_err(ERR_BAD_READ_COUNT)
                    break

                self.end += bytes_read
                if err:
                    self.set_err(err)
                    break

                if bytes_read > 0:
                    self.empties = 0
                    break

                loop += 1
                if loop > MAX_CONSECUTIVE_EMPTY_READS:
                    self.set_err(io.ERR_NO_PROGRESS)
                    break

    fn set_err(inout self, err: Error):
        """Set the internal error field to the provided error.

        Args:
            err: The error to set.
        """
        if self.err:
            var value = str(self.err)
            if value == "" or value == str(io.EOF):
                self.err = err
        else:
            self.err = err

    fn advance(inout self, n: Int) -> Bool:
        """Consumes n bytes of the buffer. It reports whether the advance was legal.

        Args:
            n: The number of bytes to advance the buffer by.

        Returns:
            True if the advance was legal, False otherwise.
        """
        if n < 0:
            self.set_err(ERR_NEGATIVE_ADVANCE)
            return False

        if n > self.end - self.start:
            self.set_err(ERR_ADVANCE_TOO_FAR)
            return False

        self.start += n
        return True


alias SplitFunction = fn (data: Span[UInt8], at_eof: Bool) -> (
    Int,
    List[UInt8],
    Error,
)
"""SplitFunction is the signature of the split function used to tokenize the
input. The arguments are an initial substring of the remaining unprocessed
data and a flag, at_eof, that reports whether the [Reader] has no more data
to give. The return values are the number of bytes to advance the input
and the next token to return to the user, if any, plus an error, if any.

Scanning stops if the function returns an error, in which case some of
the input may be discarded. If that error is [ERR_FINAL_TOKEN], scanning
stops with no error. A non-nil token delivered with [ERR_FINAL_TOKEN]
will be the last token, and a nil token with [ERR_FINAL_TOKEN]
immediately stops the scanning.

Otherwise, the [Scanner] advances the input. If the token is not nil,
the [Scanner] returns it to the user. If the token is nil, the
Scanner reads more data and continues scanning; if there is no more
data--if at_eof was True--the [Scanner] returns. If the data does not
yet hold a complete token, for instance if it has no newline while
scanning lines, a [SplitFunction] can return (0, nil, nil) to signal the
[Scanner] to read more data Into the slice and try again with a
longer slice starting at the same poInt in the input.

The function is never called with an empty data slice unless at_eof
is True. If at_eof is True, however, data may be non-empty and,
as always, holds unprocessed text."""

# Errors returned by Scanner.
alias ERR_TOO_LONG = Error("bufio.Scanner: token too long")
alias ERR_NEGATIVE_ADVANCE = Error("bufio.Scanner: SplitFunction returns negative advance count")
alias ERR_ADVANCE_TOO_FAR = Error("bufio.Scanner: SplitFunction returns advance count beyond input")
alias ERR_BAD_READ_COUNT = Error("bufio.Scanner: Read returned impossible count")


alias ERR_FINAL_TOKEN = Error("final token")
"""ERR_FINAL_TOKEN is a special sentinel error value. It is Intended to be
returned by a split function to indicate that the scanning should stop
with no error. If the token being delivered with this error is not nil,
the token is the last token.

The value is useful to stop processing early or when it is necessary to
deliver a final empty token (which is different from a nil token).
One could achieve the same behavior with a custom error value but
providing one here is tidier.
See the emptyFinalToken example for a use of this value."""


alias MAX_SCAN_TOKEN_SIZE = 64 * 1024
"""MAX_SCAN_TOKEN_SIZE is the maximum size used to buffer a token
unless the user provides an explicit buffer with [Scanner.buffer].
The actual maximum token size may be smaller as the buffer
may need to include, for instance, a newline."""

alias START_BUF_SIZE = 4096
"""Size of initial allocation for buffer."""


###### split functions ######
fn scan_bytes(data: Span[UInt8], at_eof: Bool) -> (Int, List[UInt8], Error):
    """Returns each byte as a token.

    Args:
        data: The data to split.
        at_eof: Whether the data is at the end of the file.

    Returns:
        The number of bytes to advance the input, token in bytes, and an error if one occurred.
    """
    if at_eof and len(data) == 0:
        return 0, List[UInt8](), Error()

    return 1, List[UInt8](data[0:1]), Error()


# TODO: Fix this and uncomment it.
# fn scan_runes(data: Span[UInt8], at_eof: Bool) -> (Int, List[UInt8], Error):
#     """Returns each UTF-8 encoded rune as a token.

#     Args:
#         data: The data to split.
#         at_eof: Whether the data is at the end of the file.

#     Returns:
#         The number of bytes to advance the input, token in bytes, and an error if one occurred.
#     """
#     if at_eof and len(data) == 0:
#         return 0, List[UInt8](), Error()

#     # Number of bytes of the current character
#     var lhs = (SIMD[size=1].load(UnsafePointer[Scalar[DType.uint8]](data.unsafe_ptr())) >> 7 == 0 * 1).cast[DType.uint8]()
#     var rhs = countl_zero(~SIMD[size=1].load(UnsafePointer[Scalar[DType.uint8]](data.unsafe_ptr())))
#     var char_length = int(lhs + rhs)

#     # Copy N bytes into new pointer and construct List.
#     var sp = UnsafePointer[UInt8].alloc(char_length)
#     memcpy(sp, data.unsafe_ptr(), char_length)
#     var result = List[UInt8](unsafe_pointer=sp, size=char_length, capacity=char_length)

#     return char_length, result, Error()


fn drop_carriage_return(data: Span[UInt8]) -> List[UInt8]:
    """Drops a terminal \r from the data.

    Args:
        data: The data to strip.

    Returns:
        The stripped data.
    """
    # In the case of a \r ending without a \n, indexing on -1 doesn't work as it finds a null terminator instead of \r.
    if len(data) > 0 and data[-1] == ord("\r"):
        return data[:-1]

    return data


fn scan_lines(data: Span[UInt8], at_eof: Bool) -> (Int, List[UInt8], Error):
    """Returns each line of text, stripped of any trailing end-of-line marker. The returned line may
    be empty. The end-of-line marker is one optional carriage return followed
    by one mandatory newline. The last non-empty line of input will be returned even if it has no
    newline.

    Args:
        data: The data to split.
        at_eof: Whether the data is at the end of the file.

    Returns:
        The number of bytes to advance the input.
    """
    if at_eof and len(data) == 0:
        return 0, List[UInt8](), Error()

    var i = index_byte(data, ord("\n"))
    if i >= 0:
        # We have a full newline-terminated line.
        return i + 1, drop_carriage_return(data[0:i]), Error()

    # If we're at EOF, we have a final, non-terminated line. Return it.
    # if at_eof:
    return len(data), drop_carriage_return(data), Error()

    # Request more data.
    # return 0


fn is_space(r: UInt8) -> Bool:
    alias ALL_WHITESPACES: String = " \t\n\r\x0b\f"
    if chr(int(r)) in ALL_WHITESPACES:
        return True
    return False


# TODO: Handle runes and utf8 decoding. For now, just assuming single byte length.
fn scan_words(data: Span[UInt8], at_eof: Bool) -> (Int, List[UInt8], Error):
    """Returns each space-separated word of text, with surrounding spaces deleted. It will
    never return an empty string.

    Args:
        data: The data to split.
        at_eof: Whether the data is at the end of the file.

    Returns:
        The number of bytes to advance the input, token in bytes, and an error if one occurred.
    """
    # Skip leading spaces.
    var start = 0
    var width = 0
    while start < len(data):
        width = len(data[0])
        if not is_space(data[0]):
            break

        start += width

    # Scan until space, marking end of word.
    var i = 0
    width = 0
    start = 0
    while i < len(data):
        width = len(data[i])
        if is_space(data[i]):
            return i + width, List[UInt8](data[start:i]), Error()

        i += width

    # If we're at EOF, we have a final, non-empty, non-terminated word. Return it.
    if at_eof and len(data) > start:
        return len(data), List[UInt8](data[start:]), Error()

    # Request more data.
    return start, List[UInt8](), Error()
